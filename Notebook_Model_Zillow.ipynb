{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filename = 'data/features/CON_feats_remarks.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Train Split, Response = 'SOLDPRICE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features from zillow:  10\n",
      "Number of features from redfin:  20\n",
      "Number of features from images:  2048\n",
      "Number of features from remarks:  20\n",
      "Number of training samples:  36842\n",
      "Number of validation samples:  4094\n"
     ]
    }
   ],
   "source": [
    "response_col = 'SOLDPRICE'\n",
    "test_size = 0.1\n",
    "random_state = 9001\n",
    "\n",
    "# read in data \n",
    "df = utils.read_preprocess_df(data_filename, response_col=response_col)\n",
    "\n",
    "# test train split\n",
    "X_train_dict, X_val_dict, y_train, y_val = utils.split_normalize_df(df=df, response_col=response_col, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = X_train_dict['zillow']\n",
    "val_features = X_val_dict['zillow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge model: \n",
      "best alpha:  3.5\n",
      "----- Training scores -----\n",
      "R2 on log scale:  0.32590789177462154\n",
      "MAE on log scale:  0.4587657640333033\n",
      "MAE on original $ scale:  218948.52798658473\n",
      "----- Validation scores -----\n",
      "R2 on log scale:  0.30939790240028997\n",
      "MAE on log scale:  0.4586051205574458\n",
      "MAE on original $ scale:  240399.85392549518\n"
     ]
    }
   ],
   "source": [
    "# Ridge\n",
    "filename = 'models/soldprice/data_models/condo_price_zillow_ridge.pkl'\n",
    "\n",
    "print(\"Ridge model: \")\n",
    "# t0 = time.time()\n",
    "\n",
    "# # train and save model\n",
    "# model = RidgeCV(alphas=(3.5, 4, 4.5, 5, 5.5))\n",
    "# utils.train_save_model(model, X=train_features, y=y_train, filename=filename)\n",
    "# print(\"training time: \", time.time()-t0)\n",
    "\n",
    "# load savced model and evaluate model performance\n",
    "utils.load_eval_model(filename=filename, X_train=train_features, X_val=val_features, y_train=y_train, y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "filename = 'models/soldprice/data_models/condo_price_zillow_XGBoost.pkl'\n",
    "params = {\n",
    "    'max_depth':range(21,28,2),\n",
    "    'gamma':[i/10.0 for i in range(0,3)],\n",
    "    'reg_alpha':[1e-2, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "print(\"XGBoost model: \")\n",
    "# t0 = time.time()\n",
    "\n",
    "# model\n",
    "# model = XGBRegressor(random_seed=9001)\n",
    "# grid = GridSearchCV(model, params, verbose=1, n_jobs=-1)\n",
    "\n",
    "# train and save model\n",
    "# utils.train_save_model(model, X=train_features, y=y_train, filename=filename)\n",
    "# print(\"training time: \", time.time()-t0)\n",
    "\n",
    "# load savced model and evaluate model performance\n",
    "utils.load_eval_model(filename=filename, X_train=train_features, X_val=val_features, y_train=y_train, y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light GBM\n",
    "filename = 'models/soldprice/data_models/condo_price_zillow_LGBM.pkl'\n",
    "params = {'num_leaves': [30, 100, 200], \n",
    "          'max_depth':[-1, 16, 32, 64], \n",
    "          'learning_rate':[0.01, 0.1, 1], \n",
    "          'n_estimators':[128, 256, 512]\n",
    "         }\n",
    "\n",
    "print(\"Light GBM model: \")\n",
    "# t0 = time.time()\n",
    "\n",
    "# model\n",
    "# model = model = LGBMRegressor(random_state=9001)\n",
    "# grid = GridSearchCV(model, params, verbose=1, n_jobs=-1)\n",
    "\n",
    "# train and save model\n",
    "# utils.train_save_model(model, X=train_features, y=y_train, filename=filename)\n",
    "# print(\"training time: \", time.time()-t0)\n",
    "\n",
    "# load savced model and evaluate model performance\n",
    "utils.load_eval_model(filename=filename, X_train=train_features, X_val=val_features, y_train=y_train, y_val=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Train Split, Response = 'DOM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features from zillow:  10\n",
      "Number of features from redfin:  20\n",
      "Number of features from images:  2048\n",
      "Number of features from remarks:  20\n",
      "Number of training samples:  36842\n",
      "Number of validation samples:  4094\n"
     ]
    }
   ],
   "source": [
    "response_col = 'DOM'\n",
    "test_size = 0.1\n",
    "random_state = 9001\n",
    "\n",
    "# read in data \n",
    "df = utils.read_preprocess_df(data_filename, response_col=response_col)\n",
    "\n",
    "# test train split\n",
    "X_train_dict, X_val_dict, y_train, y_val = utils.split_normalize_df(df=df, response_col=response_col, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = X_train_dict['zillow']\n",
    "val_features = X_val_dict['zillow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge model: \n",
      "best alpha:  1.5\n",
      "----- Training scores -----\n",
      "R2 on log scale:  0.03132535857505869\n",
      "MAE on log scale:  0.20420263588251353\n",
      "MAE on original $ scale:  0.7271013647650538\n",
      "----- Validation scores -----\n",
      "R2 on log scale:  0.02520524971485172\n",
      "MAE on log scale:  0.20932643183401634\n",
      "MAE on original $ scale:  0.7441632171191556\n"
     ]
    }
   ],
   "source": [
    "# Ridge\n",
    "filename = 'models/dom/data_models/condo_dom_zillow_ridge.pkl'\n",
    "\n",
    "print(\"Ridge model: \")\n",
    "# t0 = time.time()\n",
    "\n",
    "# # train and save model\n",
    "# model = RidgeCV(alphas=(3.5, 4, 4.5, 5, 5.5))\n",
    "# utils.train_save_model(model, X=train_features, y=y_train, filename=filename)\n",
    "# print(\"training time: \", time.time()-t0)\n",
    "\n",
    "# load savced model and evaluate model performance\n",
    "utils.load_eval_model(filename=filename, X_train=train_features, X_val=val_features, y_train=y_train, y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "filename = 'models/dom/data_models/condo_dom_zillow_XGBoost.pkl'\n",
    "params = {\n",
    "    'max_depth':range(21,28,2),\n",
    "    'gamma':[i/10.0 for i in range(0,3)],\n",
    "    'reg_alpha':[1e-2, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "print(\"XGBoost model: \")\n",
    "# t0 = time.time()\n",
    "\n",
    "# model\n",
    "# model = XGBRegressor(random_seed=9001)\n",
    "# grid = GridSearchCV(model, params, verbose=1, n_jobs=-1)\n",
    "\n",
    "# train and save model\n",
    "# utils.train_save_model(model, X=train_features, y=y_train, filename=filename)\n",
    "# print(\"training time: \", time.time()-t0)\n",
    "\n",
    "# load savced model and evaluate model performance\n",
    "utils.load_eval_model(filename=filename, X_train=train_features, X_val=val_features, y_train=y_train, y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light GBM\n",
    "filename = 'models/dom/data_models/condo_dom_zillow_LGBM.pkl'\n",
    "params = {'num_leaves': [30, 100, 200], \n",
    "          'max_depth':[-1, 16, 32, 64], \n",
    "          'learning_rate':[0.01, 0.1, 1], \n",
    "          'n_estimators':[128, 256, 512]\n",
    "         }\n",
    "\n",
    "print(\"Light GBM model: \")\n",
    "# t0 = time.time()\n",
    "\n",
    "# model\n",
    "# model = model = LGBMRegressor(random_state=9001)\n",
    "# grid = GridSearchCV(model, params, verbose=1, n_jobs=-1)\n",
    "\n",
    "# train and save model\n",
    "# utils.train_save_model(model, X=train_features, y=y_train, filename=filename)\n",
    "# print(\"training time: \", time.time()-t0)\n",
    "\n",
    "# load savced model and evaluate model performance\n",
    "utils.load_eval_model(filename=filename, X_train=train_features, X_val=val_features, y_train=y_train, y_val=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filename = 'data/features/MF_feats_remarks.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Train Split, Response = 'SOLDPRICE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features from zillow:  10\n",
      "Number of features from redfin:  20\n",
      "Number of features from images:  2048\n",
      "Number of features from remarks:  20\n",
      "Number of training samples:  11965\n",
      "Number of validation samples:  1330\n"
     ]
    }
   ],
   "source": [
    "response_col = 'SOLDPRICE'\n",
    "test_size = 0.1\n",
    "random_state = 9001\n",
    "\n",
    "# read in data \n",
    "df = utils.read_preprocess_df(data_filename, response_col=response_col)\n",
    "\n",
    "# test train split\n",
    "X_train_dict, X_val_dict, y_train, y_val = utils.split_normalize_df(df=df, response_col=response_col, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = X_train_dict['zillow']\n",
    "val_features = X_val_dict['zillow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge\n",
    "filename = 'models/soldprice/data_models/mf_price_zillow_ridge.pkl'\n",
    "\n",
    "print(\"Ridge model: \")\n",
    "# t0 = time.time()\n",
    "\n",
    "# # train and save model\n",
    "# model = RidgeCV(alphas=(3.5, 4, 4.5, 5, 5.5))\n",
    "# utils.train_save_model(model, X=train_features, y=y_train, filename=filename)\n",
    "# print(\"training time: \", time.time()-t0)\n",
    "\n",
    "# load savced model and evaluate model performance\n",
    "utils.load_eval_model(filename=filename, X_train=train_features, X_val=val_features, y_train=y_train, y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "filename = 'models/soldprice/data_models/mf_price_zillow_XGBoost.pkl'\n",
    "params = {\n",
    "    'max_depth':range(21,28,2),\n",
    "    'gamma':[i/10.0 for i in range(0,3)],\n",
    "    'reg_alpha':[1e-2, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "print(\"XGBoost model: \")\n",
    "# t0 = time.time()\n",
    "\n",
    "# model\n",
    "# model = XGBRegressor(random_seed=9001)\n",
    "# grid = GridSearchCV(model, params, verbose=1, n_jobs=-1)\n",
    "\n",
    "# train and save model\n",
    "# utils.train_save_model(model, X=train_features, y=y_train, filename=filename)\n",
    "# print(\"training time: \", time.time()-t0)\n",
    "\n",
    "# load savced model and evaluate model performance\n",
    "utils.load_eval_model(filename=filename, X_train=train_features, X_val=val_features, y_train=y_train, y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light GBM\n",
    "filename = 'models/soldprice/data_models/mf_price_zillow_LGBM.pkl'\n",
    "params = {'num_leaves': [30, 100, 200], \n",
    "          'max_depth':[-1, 16, 32, 64], \n",
    "          'learning_rate':[0.01, 0.1, 1], \n",
    "          'n_estimators':[128, 256, 512]\n",
    "         }\n",
    "\n",
    "print(\"Light GBM model: \")\n",
    "# t0 = time.time()\n",
    "\n",
    "# model\n",
    "# model = model = LGBMRegressor(random_state=9001)\n",
    "# grid = GridSearchCV(model, params, verbose=1, n_jobs=-1)\n",
    "\n",
    "# train and save model\n",
    "# utils.train_save_model(model, X=train_features, y=y_train, filename=filename)\n",
    "# print(\"training time: \", time.time()-t0)\n",
    "\n",
    "# load savced model and evaluate model performance\n",
    "utils.load_eval_model(filename=filename, X_train=train_features, X_val=val_features, y_train=y_train, y_val=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Train Split, Response = 'DOM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features from zillow:  10\n",
      "Number of features from redfin:  20\n",
      "Number of features from images:  2048\n",
      "Number of features from remarks:  20\n",
      "Number of training samples:  11965\n",
      "Number of validation samples:  1330\n"
     ]
    }
   ],
   "source": [
    "response_col = 'DOM'\n",
    "test_size = 0.1\n",
    "random_state = 9001\n",
    "\n",
    "# read in data \n",
    "df = utils.read_preprocess_df(data_filename, response_col=response_col)\n",
    "\n",
    "# test train split\n",
    "X_train_dict, X_val_dict, y_train, y_val = utils.split_normalize_df(df=df, response_col=response_col, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge model: \n",
      "best alpha:  1.5\n",
      "----- Training scores -----\n",
      "R2 on log log scale:  0.018471819071555595\n",
      "MAE on log log scale:  0.20791159116947272\n",
      "MAE on original scale:  0.7631119067575725\n",
      "----- Validation scores -----\n",
      "R2 on log log scale:  0.02921156058375185\n",
      "MAE on log log scale:  0.20720777894194073\n",
      "MAE on original scale:  0.7611628113193962\n"
     ]
    }
   ],
   "source": [
    "# Ridge\n",
    "filename = 'models/dom/data_models/mf_dom_zillow_ridge.pkl'\n",
    "\n",
    "print(\"Ridge model: \")\n",
    "# t0 = time.time()\n",
    "\n",
    "# # train and save model\n",
    "# model = RidgeCV(alphas=(3.5, 4, 4.5, 5, 5.5))\n",
    "# utils.train_save_model(model, X=train_features, y=y_train, filename=filename)\n",
    "# print(\"training time: \", time.time()-t0)\n",
    "\n",
    "# load savced model and evaluate model performance\n",
    "utils.load_eval_model(filename=filename, X_train=train_features, X_val=val_features, y_train=y_train, y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "filename = 'models/dom/data_models/mf_dom_zillow_XGBoost.pkl'\n",
    "params = {\n",
    "    'max_depth':range(21,28,2),\n",
    "    'gamma':[i/10.0 for i in range(0,3)],\n",
    "    'reg_alpha':[1e-2, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "print(\"XGBoost model: \")\n",
    "t0 = time.time()\n",
    "\n",
    "# model\n",
    "model = XGBRegressor(random_seed=9001)\n",
    "grid = GridSearchCV(model, params, verbose=1, n_jobs=-1)\n",
    "\n",
    "# train and save model\n",
    "utils.train_save_model(model, X=train_features, y=y_train, filename=filename)\n",
    "print(\"training time: \", time.time()-t0)\n",
    "\n",
    "# load savced model and evaluate model performance\n",
    "utils.load_eval_model(filename=filename, X_train=train_features, X_val=val_features, y_train=y_train, y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light GBM\n",
    "filename = 'models/dom/data_models/mf_dom_zillow_LGBM.pkl'\n",
    "params = {'num_leaves': [30, 100, 200], \n",
    "          'max_depth':[-1, 16, 32, 64], \n",
    "          'learning_rate':[0.01, 0.1, 1], \n",
    "          'n_estimators':[128, 256, 512]\n",
    "         }\n",
    "\n",
    "print(\"Light GBM model: \")\n",
    "t0 = time.time()\n",
    "\n",
    "# model\n",
    "model = model = LGBMRegressor(random_state=9001)\n",
    "grid = GridSearchCV(model, params, verbose=1, n_jobs=-1)\n",
    "\n",
    "# train and save model\n",
    "utils.train_save_model(model, X=train_features, y=y_train, filename=filename)\n",
    "print(\"training time: \", time.time()-t0)\n",
    "\n",
    "# load savced model and evaluate model performance\n",
    "utils.load_eval_model(filename=filename, X_train=train_features, X_val=val_features, y_train=y_train, y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
