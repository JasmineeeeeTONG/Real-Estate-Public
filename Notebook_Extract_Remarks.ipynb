{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "color = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, n_top_words):\n",
    "    topic_top_words = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        top_words_str = \" \".join(top_words)\n",
    "        print(top_words_str)\n",
    "        topic_top_words.append(top_words_str)\n",
    "    return topic_top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "proptype = 'CON'\n",
    "\n",
    "with open('data/features/{}_feats_remarks.pkl'.format(proptype), 'rb') as file:\n",
    "    feats_train = pickle.load(file)\n",
    "\n",
    "with open('data/features/TEST_{}_feats_remarks.pkl'.format(proptype), 'rb') as file:\n",
    "    feats_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_train shape: (40936, 2086)\n",
      "feats_test shape: (3563, 2086)\n"
     ]
    }
   ],
   "source": [
    "rmk_features = [col for col in feats_train.columns if 'lda_' in col or 'nmf_' in col]\n",
    "feats_train.drop(rmk_features, axis=1, inplace=True)\n",
    "feats_test.drop(rmk_features, axis=1, inplace=True)\n",
    "print('feats_train shape:', feats_train.shape)\n",
    "print('feats_test shape:', feats_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: shape(rmk + feats): (40936, 2087)\n",
      "TEST: shape(rmk + feats): (3563, 2087)\n"
     ]
    }
   ],
   "source": [
    "# merge remarks with all other features\n",
    "if proptype == 'SF':\n",
    "    rmk_train = pd.read_csv('data/merge_sold_data/MERGE_{}_SOLD.csv'.format(proptype), usecols=['MLSNUM','REMARKS'])\n",
    "    rmk_test = pd.read_csv('data/test_set/MERGE_TEST.csv', usecols=['MLSNUM','REMARKS'])\n",
    "else:\n",
    "    rmk_train = pd.read_csv('data/merge_sold_data/MERGE_{}_SOLD.csv'.format(proptype), usecols=['MLSNUM','REMARKS'],\n",
    "                       dtype={'MLSNUM': str})\n",
    "    rmk_test = pd.read_csv('data/test_set/TEST_{}.csv'.format(proptype), usecols=['MLSNUM','REMARKS'])\n",
    "\n",
    "feats_rmk_train = feats_train.merge(rmk_train, how='inner', on='MLSNUM')\n",
    "feats_rmk_test = feats_test.merge(rmk_test, how='inner', on='MLSNUM')\n",
    "\n",
    "print('TRAIN: shape(rmk + feats):', feats_rmk_train.shape)\n",
    "print('TEST: shape(rmk + feats):', feats_rmk_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill missing remarks\n",
    "feats_rmk_train['REMARKS'].fillna('', inplace=True)\n",
    "feats_rmk_test['REMARKS'].fillna('', inplace=True)\n",
    "sum(feats_rmk_train.REMARKS.isnull()), sum(feats_rmk_test.REMARKS.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Total 40936 remarks (documents)\n",
      "TEST: Total 3563 remarks (documents)\n",
      "Total 127 stop_words\n",
      "transformed tfidf_train.shape = (40936, 23031), tf_train.shape = (40936, 23031)\n",
      "transformed tfidf_test.shape = (3563, 23031), tf_test.shape = (3563, 23031)\n"
     ]
    }
   ],
   "source": [
    "# Process remarks\n",
    "doc_train = list(feats_rmk_train['REMARKS'])\n",
    "doc_test = list(feats_rmk_test['REMARKS'])\n",
    "print('TRAIN: Total {} remarks (documents)'.format(len(doc_train)))\n",
    "print('TEST: Total {} remarks (documents)'.format(len(doc_test)))\n",
    "\n",
    "# read the NLTK listed stop_words\n",
    "stop_words = []\n",
    "f = open('nltk_stop_words.txt')\n",
    "for word in f.readlines():\n",
    "    stop_words.append(word.strip())\n",
    "\n",
    "print('Total {} stop_words'.format(len(stop_words)))\n",
    "\n",
    "# transform documents to tfidf for NMF\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(doc_train)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# transform documents to raw term counts for LDA\n",
    "tf_vectorizer = CountVectorizer(stop_words=stop_words)\n",
    "tf_train = tf_vectorizer.fit_transform(doc_train)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print('transformed tfidf_train.shape = {}, tf_train.shape = {}'.format(tfidf_train.shape, tf_train.shape))\n",
    "\n",
    "tfidf_test = tfidf_vectorizer.transform(doc_test)\n",
    "tf_test = tf_vectorizer.transform(doc_test)\n",
    "print('transformed tfidf_test.shape = {}, tf_test.shape = {}'.format(tfidf_test.shape, tf_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_vocabulary = tfidf_vectorizer.vocabulary_\n",
    "# tf_vocabulary = tf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NMF top topics ===\n",
      "Topic 0:\n",
      "master closet suite walk custom bath\n",
      "Topic 1:\n",
      "unit great condo location close well\n",
      "Topic 2:\n",
      "boston building street high parking square\n",
      "Topic 3:\n",
      "new brand flooring painted updated appliances\n",
      "Topic 4:\n",
      "pool tennis room courts amenities club\n",
      "Topic 5:\n",
      "community baths today homes call appointment\n",
      "Topic 6:\n",
      "room level family home living finished\n",
      "Topic 7:\n",
      "water fee hot heat condo includes\n",
      "Topic 8:\n",
      "house 12 30 sunday 00 open\n",
      "Topic 9:\n",
      "floor first second bath full two\n",
      "\n",
      "=== LDA top topics ===\n",
      "Topic 0:\n",
      "views building concierge center boston fitness\n",
      "Topic 1:\n",
      "boston views home square city restaurants\n",
      "Topic 2:\n",
      "room floor bath living master kitchen\n",
      "Topic 3:\n",
      "charles park longwood mall score brookline\n",
      "Topic 4:\n",
      "buyer property seller offers condo owner\n",
      "Topic 5:\n",
      "new custom appliances stainless high lighting\n",
      "Topic 6:\n",
      "floor condo community unit new units\n",
      "Topic 7:\n",
      "davis finish gated lofts arboretum loft\n",
      "Topic 8:\n",
      "unit kitchen condo new bedroom room\n",
      "Topic 9:\n",
      "minutes mass 495 harvard pike commuter\n"
     ]
    }
   ],
   "source": [
    "n_components = 10\n",
    "# Run NMF\n",
    "nmf = NMF(n_components=n_components, random_state=9001, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf_train)\n",
    "nmf_train = nmf.transform(tfidf_train)\n",
    "nmf_test = nmf.transform(tfidf_test)\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_components=n_components, learning_method='online', learning_offset=50., random_state=9001).fit(tf_train)\n",
    "lda_train = lda.transform(tf_train)\n",
    "lda_test = lda.transform(tf_test)\n",
    "\n",
    "# Print top topics\n",
    "n_top_words = 6\n",
    "print('=== NMF top topics ===')\n",
    "nmf_topics = display_topics(nmf, tfidf_feature_names, n_top_words)\n",
    "print('\\n=== LDA top topics ===')\n",
    "lda_topics = display_topics(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataframe for remark topics\n",
    "nmf_cols = ['nmf_{}'.format(i) for i in range(nmf_train.shape[1])]\n",
    "lda_cols = ['lda_{}'.format(i) for i in range(lda_train.shape[1])]\n",
    "\n",
    "df_nmf_train = pd.DataFrame(nmf_train, index=feats_rmk_train.index, columns=nmf_cols)\n",
    "df_lda_train = pd.DataFrame(lda_train, index=feats_rmk_train.index, columns=lda_cols)\n",
    "df_nmf_test = pd.DataFrame(nmf_test, index=feats_rmk_test.index, columns=nmf_cols)\n",
    "df_lda_test = pd.DataFrame(lda_test, index=feats_rmk_test.index, columns=lda_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: shape(feats + transfromed rmk):  (40936, 2107)\n",
      "TEST: shape(feats + transfromed rmk):  (3563, 2107)\n"
     ]
    }
   ],
   "source": [
    "# Merge dataframes\n",
    "feats_rmk_transformed_train = pd.concat((feats_rmk_train, df_nmf_train, df_lda_train), axis=1)\n",
    "feats_rmk_transformed_test = pd.concat((feats_rmk_test, df_nmf_test, df_lda_test), axis=1)\n",
    "print('TRAIN: shape(feats + transfromed rmk): ', feats_rmk_transformed_train.shape)\n",
    "print('TEST: shape(feats + transfromed rmk): ', feats_rmk_transformed_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save \n",
    "feats_rmk_transformed_train.to_pickle('data/features/TRAIN_{}.pkl'.format(proptype))\n",
    "feats_rmk_transformed_test.to_pickle('data/features/TEST_{}.pkl'.format(proptype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
